#se cargan los paquetes necesarios
require(pacman)
p_load(tidyverse, rvest)
load("C:/Users/mlara/OneDrive/Documents/.RData")
rm(list=ls())
require(pacman)
p_load(tidyverse, rvest)
#Se crea un vector con los links de las páginas dónde están los datos
url_base <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", 1:10, ".html")
url_base #visualización del vector
#Iterando en cada uno de los urls de la página se descargan los datos  y se juntan en un data frame
dt <- data.frame()
for (url in url_base) {
print(url)
temp <- read_html(url) %>%
html_table()
temp <- as.data.frame(temp[[1]])
dt <- rbind(dt, temp)
}
dt #el data frame resultante tiene 178 variables y 32177 observaciones
# Limpieza de datos -------------------------------------------------------
dt_mayores <- dt %>% subset(age>=18) #depuramos a todos los menores de edad
sum(apply(dt_mayores, 1, anyNA))#contamos las filas que contienen NAs
na_count <-sapply(x, function(y) sum(length(which(is.na(y)))))
na_count <-sapply(dt, function(y) sum(length(which(is.na(y)))))
cbind(colnames(dt_mayores), na_count)
na_count <-sapply(dt_mayores, function(y) sum(length(which(is.na(y)))))
cbind(colnames(dt_mayores), na_count)
na_cols <- cbind(colnames(dt_mayores), na_count)
na_cols <- as.data.frame(cbind(colnames(dt_mayores), na_count))
View(na_cols)
head(dt_mayores$iof2)
sum(dt_mayores$iof2)
sum(dt_mayores$iof2, dt_mayores$iof2es)
dt_sin_jubilados <- dt_mayores %>% subset(iof2==0)
write.csv(dt, file = "data_ps1.csv")
save.image("C:/Users/mlara/Desktop/BD&ML/Problem Set 1/ps1.bdml/data_ps1.RData")
